{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des fonctions définies dans le module `lib` (contient les fonctions pour le processing de l'audio et la création de modèles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import audio_processing, modeling, prediction, save_model, load_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import de quelques modules complémentaires afin de visualiser les résultats et les modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "from os import listdir,system\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer des prédictions, on va avoir besoin de générer des spectrogrammes depuis les fichiers audio, car les modèles sont entraînés grâce à ce type de données. Techniquement, on fait appel à la fonction `audio_processing` pour cela. On est ici sur un petit exemple, on va donc ne pas utiliser le multiprocessing, en revanche l'appel à cette fonction par le `main` le prend en charge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:Processing specie 'blujay'\n",
      "C:\\Users\\Tharos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Tharos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "CRITICAL:root:Processing specie 'bushti'\n",
      "CRITICAL:root:Processing specie 'cacwre'\n",
      "CRITICAL:root:Processing specie 'comyel'\n",
      "CRITICAL:root:Processing specie 'haiwoo'\n"
     ]
    }
   ],
   "source": [
    "audio_folder:str = \"toy_data\"\n",
    "output:str = \"toy_train\"\n",
    "\n",
    "for specie in listdir(audio_folder):\n",
    "    Path(f\"{output}/{specie}\").mkdir(parents=True, exist_ok=True)\n",
    "    audio_processing(audio_folder,output,specie)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de créer un modèle, on doit définir un certain nombre de paramètres, notamment d'architecture. Sont listés ici les paramètres d'un modèle présenté lors de la présentation orale, nommé 'modèle à 6 couches'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT: int = 500  # nb de pixels en hauteur\n",
    "WIDTH: int = 400  # nb de pixels en largeur\n",
    "\n",
    "MODEL_PARAMS: dict = {\n",
    "    'model_name': '256_filtered_6L_30sp',\n",
    "    'epochs': 100,\n",
    "    'early_stopping': True,\n",
    "    'batch': 256,\n",
    "    'validation_split': 0.2,\n",
    "    'layer_01_filter_count': 8,\n",
    "    'layer_02_filter_count': 8,\n",
    "    'layer_03_filter_count': 16,\n",
    "    'layer_04_filter_count': 32,\n",
    "    'layer_05_filter_count': 32,\n",
    "    'layer_06_filter_count': 16,\n",
    "    'layer_01_kernel_size': 5,\n",
    "    'layer_02_kernel_size': 3,\n",
    "    'layer_03_kernel_size': 3,\n",
    "    'layer_04_kernel_size': 3,\n",
    "    'layer_05_kernel_size': 3,\n",
    "    'layer_06_kernel_size': 3,\n",
    "    'layer_dense_size': 64,\n",
    "    'dropout': 0.2,\n",
    "    'num_layers': 6,\n",
    "    'l1_regularization': 0.0,\n",
    "    'l2_regularization': 0.01\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant pouvoir entraîner le modèle sur nos données que l'on vient de produire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 679 files belonging to 5 classes.\n",
      "Using 544 files for training.\n",
      "Found 679 files belonging to 5 classes.\n",
      "Using 135 files for validation.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 500, 400, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 500, 400, 8)       608       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 250, 200, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 250, 200, 8)       584       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 125, 100, 8)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 125, 100, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 62, 50, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 62, 50, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 31, 25, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 31, 25, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 15, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 15, 12, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 7, 6, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 672)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 672)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                43072     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,269\n",
      "Trainable params: 64,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tharos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 41s 11s/step - loss: 2.7299 - accuracy: 0.3566 - val_loss: 2.5037 - val_accuracy: 0.4815\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 2.5413 - accuracy: 0.4393 - val_loss: 2.3799 - val_accuracy: 0.4815\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 2.4138 - accuracy: 0.4393 - val_loss: 2.3044 - val_accuracy: 0.4815\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 2.3285 - accuracy: 0.4393 - val_loss: 2.1867 - val_accuracy: 0.4815\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 2.2124 - accuracy: 0.4393 - val_loss: 2.0678 - val_accuracy: 0.4815\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 2.0804 - accuracy: 0.4504 - val_loss: 1.9058 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 1.9357 - accuracy: 0.5276 - val_loss: 1.7402 - val_accuracy: 0.6444\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 1.7766 - accuracy: 0.6029 - val_loss: 1.5507 - val_accuracy: 0.6963\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 1.6296 - accuracy: 0.6305 - val_loss: 1.4257 - val_accuracy: 0.6815\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 1.5334 - accuracy: 0.6121 - val_loss: 1.4418 - val_accuracy: 0.6444\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 40s 11s/step - loss: 1.4048 - accuracy: 0.6654 - val_loss: 1.3343 - val_accuracy: 0.7111\n",
      "Epoch 12/100\n",
      "1/3 [=========>....................] - ETA: 35s - loss: 1.4217 - accuracy: 0.6484"
     ]
    }
   ],
   "source": [
    "modeling(output,HEIGHT,WIDTH,MODEL_PARAMS,True,False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle est enregistré dans le dossier `models`, et on peut y retrouver les graphes présentant les résultats sur le jeu de validation, ainsi que l'évolution des métriques en fonction des epochs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des modèles légers d'exemple (entraînés sur 5 espèces) ont été sauvegardés dans le dossier `models_samples`. On va charger un de ces modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path:str = \"models_samples/model_01\"\n",
    "\n",
    "trained_model,classes = load_model(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir les informations d'entraînement du modèle ainsi que les paramètres ayant servi à l'entraîner, sauvegardées dans un fichier .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'execution_time': 5623.843999999983,\n",
       " 'cpu_time': 17019.21875,\n",
       " 'true_epochs': 36,\n",
       " 'accuracy_train': [0.25949999690055847,\n",
       "  0.3269999921321869,\n",
       "  0.4620000123977661,\n",
       "  0.6520000100135803,\n",
       "  0.7204999923706055,\n",
       "  0.7639999985694885,\n",
       "  0.8065000176429749,\n",
       "  0.8379999995231628,\n",
       "  0.8450000286102295,\n",
       "  0.8514999747276306,\n",
       "  0.8730000257492065,\n",
       "  0.8784999847412109,\n",
       "  0.8774999976158142,\n",
       "  0.8880000114440918,\n",
       "  0.9054999947547913,\n",
       "  0.9014999866485596,\n",
       "  0.9144999980926514,\n",
       "  0.9200000166893005,\n",
       "  0.9350000023841858,\n",
       "  0.9434999823570251,\n",
       "  0.949999988079071,\n",
       "  0.953000009059906,\n",
       "  0.949999988079071,\n",
       "  0.9509999752044678,\n",
       "  0.9459999799728394,\n",
       "  0.9629999995231628,\n",
       "  0.9649999737739563,\n",
       "  0.9714999794960022,\n",
       "  0.9729999899864197,\n",
       "  0.9660000205039978,\n",
       "  0.9750000238418579,\n",
       "  0.9804999828338623,\n",
       "  0.984499990940094,\n",
       "  0.9810000061988831,\n",
       "  0.9714999794960022,\n",
       "  0.9785000085830688],\n",
       " 'loss_train': [1.6012455224990845,\n",
       "  1.5556195974349976,\n",
       "  1.3614341020584106,\n",
       "  0.9710457921028137,\n",
       "  0.7679431438446045,\n",
       "  0.6437065601348877,\n",
       "  0.5507420897483826,\n",
       "  0.486644446849823,\n",
       "  0.45441851019859314,\n",
       "  0.41942715644836426,\n",
       "  0.38233083486557007,\n",
       "  0.3659396171569824,\n",
       "  0.35192322731018066,\n",
       "  0.3068980574607849,\n",
       "  0.28147369623184204,\n",
       "  0.2857705056667328,\n",
       "  0.250339150428772,\n",
       "  0.22420501708984375,\n",
       "  0.20308706164360046,\n",
       "  0.18431037664413452,\n",
       "  0.16064181923866272,\n",
       "  0.14762532711029053,\n",
       "  0.1464693695306778,\n",
       "  0.14345699548721313,\n",
       "  0.14548370242118835,\n",
       "  0.11846346408128738,\n",
       "  0.1019323393702507,\n",
       "  0.08794920891523361,\n",
       "  0.08002062886953354,\n",
       "  0.0881657749414444,\n",
       "  0.07038761675357819,\n",
       "  0.05907028540968895,\n",
       "  0.05080018192529678,\n",
       "  0.0563775971531868,\n",
       "  0.08225471526384354,\n",
       "  0.061812106519937515],\n",
       " 'accuracy_validation': [0.2540000081062317,\n",
       "  0.3580000102519989,\n",
       "  0.5220000147819519,\n",
       "  0.6320000290870667,\n",
       "  0.6940000057220459,\n",
       "  0.722000002861023,\n",
       "  0.765999972820282,\n",
       "  0.7799999713897705,\n",
       "  0.7760000228881836,\n",
       "  0.800000011920929,\n",
       "  0.8019999861717224,\n",
       "  0.7979999780654907,\n",
       "  0.8240000009536743,\n",
       "  0.8479999899864197,\n",
       "  0.8479999899864197,\n",
       "  0.8479999899864197,\n",
       "  0.8600000143051147,\n",
       "  0.8619999885559082,\n",
       "  0.8880000114440918,\n",
       "  0.8880000114440918,\n",
       "  0.8960000276565552,\n",
       "  0.9039999842643738,\n",
       "  0.8899999856948853,\n",
       "  0.8700000047683716,\n",
       "  0.9020000100135803,\n",
       "  0.8859999775886536,\n",
       "  0.8859999775886536,\n",
       "  0.8899999856948853,\n",
       "  0.8880000114440918,\n",
       "  0.8939999938011169,\n",
       "  0.9100000262260437,\n",
       "  0.9079999923706055,\n",
       "  0.906000018119812,\n",
       "  0.8999999761581421,\n",
       "  0.9179999828338623,\n",
       "  0.8980000019073486],\n",
       " 'loss_validation': [1.5924221277236938,\n",
       "  1.4927574396133423,\n",
       "  1.194905400276184,\n",
       "  0.9862602949142456,\n",
       "  0.8361594080924988,\n",
       "  0.738608717918396,\n",
       "  0.6567553877830505,\n",
       "  0.5941199660301208,\n",
       "  0.5923404097557068,\n",
       "  0.5217900276184082,\n",
       "  0.49649474024772644,\n",
       "  0.5106396079063416,\n",
       "  0.43936046957969666,\n",
       "  0.4203869700431824,\n",
       "  0.39682886004447937,\n",
       "  0.4146130084991455,\n",
       "  0.3483857214450836,\n",
       "  0.3640529215335846,\n",
       "  0.30976346135139465,\n",
       "  0.31292426586151123,\n",
       "  0.28264063596725464,\n",
       "  0.29342442750930786,\n",
       "  0.28678157925605774,\n",
       "  0.35299184918403625,\n",
       "  0.2746037244796753,\n",
       "  0.29445862770080566,\n",
       "  0.2913402020931244,\n",
       "  0.27968287467956543,\n",
       "  0.31945353746414185,\n",
       "  0.26608508825302124,\n",
       "  0.26926618814468384,\n",
       "  0.28785812854766846,\n",
       "  0.30910205841064453,\n",
       "  0.34355005621910095,\n",
       "  0.30203014612197876,\n",
       "  0.3336370587348938],\n",
       " 'iter': 2,\n",
       " 'model_name': 'MODEL_6L_256',\n",
       " 'epochs': 100,\n",
       " 'early_stopping': True,\n",
       " 'batch': 256,\n",
       " 'validation_split': 0.2,\n",
       " 'layer_01_filter_count': 8,\n",
       " 'layer_02_filter_count': 8,\n",
       " 'layer_03_filter_count': 16,\n",
       " 'layer_04_filter_count': 32,\n",
       " 'layer_05_filter_count': 16,\n",
       " 'layer_06_filter_count': 8,\n",
       " 'layer_01_kernel_size': 5,\n",
       " 'layer_02_kernel_size': 3,\n",
       " 'layer_03_kernel_size': 5,\n",
       " 'layer_04_kernel_size': 3,\n",
       " 'layer_05_kernel_size': 3,\n",
       " 'layer_06_kernel_size': 3,\n",
       " 'layer_dense_size': 32,\n",
       " 'dropout': 0.0,\n",
       " 'num_layers': 6,\n",
       " 'l1_regularization': 0.0,\n",
       " 'l2_regularization': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load(open(f\"{model_path}/params.json\", \"r\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également récupérer les informations de structure du modèle, sauvegardées dans un fichier texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model: \"sequential_17\"\\n_________________________________________________________________\\n Layer (type)                Output Shape              Param #   \\n=================================================================\\n rescaling_17 (Rescaling)    (None, 500, 400, 3)       0         \\n                                                                 \\n conv2d_84 (Conv2D)          (None, 500, 400, 8)       608       \\n                                                                 \\n max_pooling2d_84 (MaxPoolin  (None, 250, 200, 8)      0         \\n g2D)                                                            \\n                                                                 \\n conv2d_85 (Conv2D)          (None, 250, 200, 8)       584       \\n                                                                 \\n max_pooling2d_85 (MaxPoolin  (None, 125, 100, 8)      0         \\n g2D)                                                            \\n                                                                 \\n conv2d_86 (Conv2D)          (None, 125, 100, 16)      3216      \\n                                                                 \\n max_pooling2d_86 (MaxPoolin  (None, 62, 50, 16)       0         \\n g2D)                                                            \\n                                                                 \\n conv2d_87 (Conv2D)          (None, 62, 50, 32)        4640      \\n                                                                 \\n max_pooling2d_87 (MaxPoolin  (None, 31, 25, 32)       0         \\n g2D)                                                            \\n                                                                 \\n conv2d_88 (Conv2D)          (None, 31, 25, 16)        4624      \\n                                                                 \\n max_pooling2d_88 (MaxPoolin  (None, 15, 12, 16)       0         \\n g2D)                                                            \\n                                                                 \\n conv2d_89 (Conv2D)          (None, 15, 12, 8)         1160      \\n                                                                 \\n max_pooling2d_89 (MaxPoolin  (None, 7, 6, 8)          0         \\n g2D)                                                            \\n                                                                 \\n flatten_17 (Flatten)        (None, 336)               0         \\n                                                                 \\n dropout_17 (Dropout)        (None, 336)               0         \\n                                                                 \\n dense_34 (Dense)            (None, 32)                10784     \\n                                                                 \\n dense_35 (Dense)            (None, 5)                 165       \\n                                                                 \\n=================================================================\\nTotal params: 25,781\\nTrainable params: 25,781\\nNon-trainable params: 0\\n_________________________________________________________________\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(l for l in open(f\"{model_path}/model.txt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va créer un ensemble de spectrogrammes \"inconnus\" à partir de l'espèce 'bushti'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:Processing specie 'toy_prediction'\n",
      "C:\\Users\\Tharos\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_folder:str = \"toy_unknown\"\n",
    "output:str = \"predict\"\n",
    "\n",
    "for specie in listdir(audio_folder):\n",
    "    Path(f\"{output}/{specie}\").mkdir(parents=True, exist_ok=True)\n",
    "    audio_processing(audio_folder,output,specie)\n",
    "\n",
    "system(f\"mv {output}/{specie}/* {output}/\")\n",
    "system(f\"rm -r {output}/{specie}/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va exécuter les prédictions sur les spectrogrammes que l'on vient de générer avec le modèle d'exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "[('Cactus Wren', 14.884757995605469), ('Common Yellowthroat', 14.884757995605469), ('Hairy Woodpecker', 14.884757995605469), ('Blue Jay', 14.884759485721588), ('American Bushtit', 40.46096205711365)]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[('Blue Jay', 14.884759485721588), ('Cactus Wren', 14.884759485721588), ('Common Yellowthroat', 14.884759485721588), ('Hairy Woodpecker', 14.884759485721588), ('American Bushtit', 40.460970997810364)]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[('Blue Jay', 14.884759485721588), ('Cactus Wren', 14.884759485721588), ('Common Yellowthroat', 14.884759485721588), ('Hairy Woodpecker', 14.884759485721588), ('American Bushtit', 40.460970997810364)]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[('Blue Jay', 14.884759485721588), ('Cactus Wren', 14.884759485721588), ('Common Yellowthroat', 14.884759485721588), ('Hairy Woodpecker', 14.884759485721588), ('American Bushtit', 40.460970997810364)]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[('Blue Jay', 14.884774386882782), ('Common Yellowthroat', 14.884774386882782), ('Hairy Woodpecker', 14.884774386882782), ('Cactus Wren', 14.884836971759796), ('American Bushtit', 40.46083688735962)]\n"
     ]
    }
   ],
   "source": [
    "for img in listdir(output):\n",
    "    print(sorted(prediction(f\"{output}/{img}\",trained_model,HEIGHT,WIDTH,classes),key=lambda x:x[1])[::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a7defa66b68dbab892a952df714b69469a56330ce85434a6f185867705ac253"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
